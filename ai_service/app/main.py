import os
import json
import uvicorn
import google.generativeai as genai
from fastapi import FastAPI, UploadFile, File
from pydantic import BaseModel
from typing import Optional, List
from dotenv import load_dotenv

# 1. C·∫•u h√¨nh m√¥i tr∆∞·ªùng
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("‚ö†Ô∏è C·∫¢NH B√ÅO: Ch∆∞a t√¨m th·∫•y GOOGLE_API_KEY trong .env")

genai.configure(api_key=api_key)

app = FastAPI(title="BizFlow AI Service")

# 2. ƒê·ªãnh nghƒ©a Data Models
class OrderItem(BaseModel):
    product_name: str
    quantity: float
    unit: str

class DraftOrderResponse(BaseModel):
    customer_name: Optional[str] = None
    items: List[OrderItem]
    is_debt: bool
    original_message: str

class NaturalLanguageOrderRequest(BaseModel):
    message: str
    user_id: Optional[str] = None

# 3. H√†m x·ª≠ l√Ω AI (Ph√¢n t√≠ch Text)
async def parse_order_with_gemini(message: str) -> DraftOrderResponse:
    try:
        # S·ª¨A: D√πng model chu·∫©n 'gemini-2.5-flash'
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"""
        Extract order info from this text to JSON: "{message}"
        JSON format: {{ "customer_name": "string", "items": [{{ "product_name": "string", "quantity": 1, "unit": "string" }}], "is_debt": boolean, "original_message": "string" }}
        If customer name is not found, set null.
        """
        response = model.generate_content(prompt)
        text = response.text.replace("```json", "").replace("```", "").strip()
        data = json.loads(text)
        return DraftOrderResponse(**data)
    except Exception as e:
        print(f"‚ùå L·ªói Gemini Parse: {e}")
        return DraftOrderResponse(
            customer_name=None, items=[], is_debt=False, original_message=message
        )

# 4. API Endpoints

@app.get("/")
def read_root():
    return {"status": "AI Service is running properly!"}

@app.post("/api/parse-order", response_model=DraftOrderResponse)
async def parse_order(request: NaturalLanguageOrderRequest):
    print(f"üì© Nh·∫≠n y√™u c·∫ßu: {request.message}")
    result = await parse_order_with_gemini(request.message)
    return result

# API D·ªãch gi·ªçng n√≥i (Audio) - B·ªï sung l·∫°i h√†m n√†y
@app.post("/api/orders/ai/transcribe")
async def transcribe_audio(audio: UploadFile = File(...)):
    print(f"üé§ Nh·∫≠n file √¢m thanh: {audio.filename}")
    try:
        audio_bytes = await audio.read()
        
        # S·ª¨A: D√πng model chu·∫©n 'gemini-1.5-flash'
        model = genai.GenerativeModel("gemini-2.5-flash")
        
        response = model.generate_content([
            "H√£y ch√©p l·∫°i ch√≠nh x√°c nh·ªØng g√¨ ng∆∞·ªùi n√≥i trong ƒëo·∫°n √¢m thanh n√†y b·∫±ng ti·∫øng Vi·ªát. Ch·ªâ tr·∫£ v·ªÅ vƒÉn b·∫£n, kh√¥ng th√™m l·ªùi d·∫´n.",
            {
                "mime_type": "audio/webm", 
                "data": audio_bytes
            }
        ])
        
        text = response.text.strip()
        print(f"‚úÖ Gemini nghe ƒë∆∞·ª£c: {text}")
        return {"success": True, "text": text}
    
    except Exception as e:
        print(f"‚ùå L·ªói Gemini Audio: {e}")
        # N·∫øu model 1.5 flash v·∫´n l·ªói, h√£y th·ª≠ 'models/gemini-2.5-flash-latest'
        return {"success": False, "message": f"L·ªói x·ª≠ l√Ω √¢m thanh: {str(e)}"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)